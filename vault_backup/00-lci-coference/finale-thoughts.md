

- amazing conference and I think everyone should go 
	- Fills in gaps
	- Brings up new questions 
	- Exposes us to new ideas and tools 
	- Shared experiences of success and failures which help each other navigate
- It really encouraged me a lot
- Also showed me that we are really not succeeding in this service and if we don’t address it I think it has the potential to really negatively impact research more than it has
- Software
	- Slurm
		- This is the scheduler of choice 
		- 50 attendees only 2 places not using it us and some one else
		- It is the standard and kind of the future
		- group of devs there learning
		- Munge plug and play with Slurm not sge
		- Scalability & Performance
			- Designed for large clusters, scales efficiently with thousands of nodes and jobs.
		- Active Development & Community Support 
		- Actively maintained with strong community and enterprise backing, unlike the mostly stagnant SGE.
		- Better Resource Management â€“ Supports advanced scheduling features like job dependencies, preemption, and fair share scheduling.
		- Integrated Accounting & Monitoring â€“ Built-in job tracking and resource usage monitoring with SlurmDBD.
		- Container & GPU Support â€“ Native support for Singularity, Docker, and GPUs, making it ideal for AI/ML workloads.
		- More Flexible Job Scheduling â€“ Fine-grained control over CPU, memory, and GPU allocation per job, supporting heterogeneous workloads.
		- Ease of Configuration & Maintenance â€“ Centralized configuration with simpler setup and management compared to SGEâ€™s complex file-based approach.
	- spack
	- OpenOnDemand
	- Apptainer
- User support
	- talked in great detail about work load managment and ticketing solutions and best practices 
	- Was able to talk through our exact process with the instructor
	- We really need to address this we are wasting so much cet time
	- Cherwell, or maybe RT but we need a solution
	- 
- Storage
	- So many options really depends on budget no perfect solution
	- What are the needs
	- Ceph considerations 
		- Kyle Kansas/lands loved using it would do again but….
		- Ceph does not work with rdma on infiniband…
		- They used 100g and 40g
		- I think Cody is thinking through but I want to make sure we are discussing 
- hardware
	- Hyperthreading
	- Centos 7 
	- Benchmarking






3WJJKZ6K
telegraph